{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model.gan_discriminators import patchgan70\n",
    "from model.gan_generator import ternausNet16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data loader\n",
    "img_sz=(256, 256, 3)\n",
    "dataset_name = 'facades'\n",
    "samples_pth = f'images/{dataset_name}'\n",
    "data_loader = DataLoader(dataset_name=dataset_name, img_res=img_sz[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine patch size for PatchGan\n",
    "patch = int(img_sz[0] / 2**4)\n",
    "disc_patch = (patch, patch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimiser\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build discriminator\n",
    "discriminator = patchgan70(input_size=img_sz)\n",
    "discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build generator\n",
    "generator = ternausNet16(input_size=img_sz, output_channels=3, \n",
    "                         dropout=True, batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GAN model by combining generator and \n",
    "# non-trainable discriminator\n",
    "\n",
    "x = Input(shape=img_sz) # condition\n",
    "z = generator(x)        # generated\n",
    "\n",
    "# Discriminate without training\n",
    "discriminator.trainable = False\n",
    "valid = discriminator([z, x])\n",
    "\n",
    "combined = Model(inputs=[x], outputs=[valid, z])\n",
    "combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def sample_from_model(sample_dir, epoch, batch_i):\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    r, c = 3, 3\n",
    "    \n",
    "    imgs_A, imgs_B = data_loader.load_batch(batch_size=3, is_testing=True)\n",
    "    fake_A = generator.predict(imgs_B)\n",
    "    \n",
    "    gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "    \n",
    "    # Rescale 0-1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    titles = ['Condition', 'Generated', 'Original']\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(r):\n",
    "        for j in range (c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt])\n",
    "            axs[i, j].set_title(titles[i])\n",
    "            axs[i, j].axis['off']\n",
    "            cnt += 1\n",
    "    fig.save(f'{sample_dir}/{epoch}_{batch_i}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "yo\n"
     ]
    }
   ],
   "source": [
    "def train(epochs, batch_size=1, sample_interval=50):\n",
    "    # Train\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size,) + disc_patch)  # TODO: this patch size will be wrong\n",
    "    fake  = np.ones((batch_size,) + disc_patch)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_i, (imgs_A, imgs_B) in enumerate(data_loader.load_batch(batch_size=batch_size)):\n",
    "            \n",
    "            # Train Discriminator\n",
    "            # --------------------------\n",
    "            \n",
    "            # generate some fake samples\n",
    "            fake_A = generator.predict(imgs_B)\n",
    "            \n",
    "            # train the discriminator\n",
    "            d_loss_real = discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "            d_loss_fake = discriminator.train_on_batch([fake_A, imgs_B], valid)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) # TODO: check math\n",
    "            \n",
    "            # Train Generator\n",
    "            # --------------------------\n",
    "            \n",
    "            g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "            \n",
    "            elapsed_time = datetime.now() - start_time\n",
    "            #print(f'Epoch {epoch}/{epochs} Batch {batch_i} D loss: {d_loss[0]} acc: {100*d_loss[1]} ' )\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        batch_i, self.data_loader.n_batches,\n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0],\n",
    "                                                                        elapsed_time))   \n",
    "            \n",
    "            if batch_i % sample_interval == 0:\n",
    "                sample_images(epoch, batch_i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(epochs=200, batch_size=1, sample_interval=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
